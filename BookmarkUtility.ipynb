{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import urllib\n",
    "import pickle\n",
    "from http.client import IncompleteRead\n",
    "from urllib.error import HTTPError, URLError\n",
    "from io import StringIO, BytesIO, IOBase, TextIOBase\n",
    "\n",
    "data_loc = 'data/Safari_Bookmarks_2018_12_22.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TreeNodeType(Enum):\n",
    "    FOLDED=1\n",
    "    LINK=2\n",
    "\n",
    "class TreeNode(object):\n",
    "    \"\"\"\n",
    "    TreeNode for generic tree construction.\n",
    "    \"\"\"\n",
    "    def __init__(self, _val: dict, _children: []=None):\n",
    "        assert (_val is not None) and (\"type\" in _val) and (\"name\" in _val)\n",
    "        self.val = _val\n",
    "        self.children = []\n",
    "        if _children:\n",
    "            for child in _children:\n",
    "                self.children.append(child)\n",
    "                \n",
    "    def appendChild(self, _child):\n",
    "        if _child not in self.children:\n",
    "            self.children.append(_child)\n",
    "    \n",
    "    @classmethod\n",
    "    def newTreeNode(cls, _val: dict):\n",
    "        return cls(_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forest(object):\n",
    "    \"\"\"\n",
    "    Forest constructed by list of parallel Tree from parsing html tree.\n",
    "    \"\"\"\n",
    "    def __init__(self, fname: str):\n",
    "        self.roots = []\n",
    "        self.fname = fname\n",
    "        assert os.path.exists(fname)\n",
    "        # check if end of f IOBase, record it first, then use for comparsion of closing\n",
    "        with open(self.fname, 'rb') as f:\n",
    "            # mark the end of stream, refer to https://stackoverflow.com/questions/10140281/how-to-find-out-whether-a-file-is-at-its-eof\n",
    "            f.seek(-1, os.SEEK_END); self.eof = f.tell(); f.seek(0, os.SEEK_SET)\n",
    "            while f.tell() != self.eof + 1:\n",
    "                roots = self.newTree(f)\n",
    "                self.roots.extend([x for x in roots if x])\n",
    "            \n",
    "    def newTree(self, f: TextIOBase, level: int=0, parent: TreeNode=None):\n",
    "        \"\"\"[new Tree and return root node of Tree via parsing input file handle f.]\n",
    "        Tips: \n",
    "            1. seek() and tell() to decide EOF\n",
    "            2. DON'T return root, as in AAAAAAFAAA structure is difficult to return back, then insert\n",
    "        Arguments:\n",
    "            f [IOBase] - [input file handler]\n",
    "            level [int] - [level in the current tree]\n",
    "            parent [TreeNode] - [parent node of current treeNode, if exists, otherwise, it's None]\n",
    "        Returns:\n",
    "            roots [list(TreeNode)] - list of items in tree\n",
    "        \"\"\"\n",
    "        def findFirstDT(f: TextIOBase):\n",
    "            \"\"\"\n",
    "            Need to handle with corner case: if can't find <DT>, as empty items for this group, need to stop immedidately.\n",
    "                <DT><H3 FOLDED>lldb</H3>\n",
    "                    <DL><p>\n",
    "                    </DL><p>\n",
    "            \"\"\"\n",
    "            fstart = f.tell()\n",
    "            l = f.readline().decode('utf-8'); align = l.find('<')\n",
    "            line = l.lstrip()\n",
    "            while f.tell() != self.eof + 1 and line[:4] != '<DT>' and line[:5] != '</DL>':\n",
    "                fstart = f.tell()\n",
    "                l = f.readline().decode('utf-8'); align = l.find('<')\n",
    "                line = l.lstrip()\n",
    "            if line[:5] == '</DL>' or align == -1 or f.tell() == self.eof + 1 :\n",
    "                # need to reset, as the starting item is empty for group\n",
    "                if f.tell() != self.eof + 1:\n",
    "                    f.seek(fstart, os.SEEK_SET)\n",
    "                return None, None, None, False\n",
    "            if line[:4] == '<DT>': \n",
    "                return line, align, fstart, True\n",
    "        \n",
    "        def findNextLineDT(f: TextIOBase):\n",
    "            fstart = f.tell()\n",
    "            line = f.readline().decode('utf-8'); align = line.find('<')\n",
    "            line = line.lstrip()\n",
    "            return line, align, fstart\n",
    "        \n",
    "        def createNode(content, f: TextIOBase, parent):\n",
    "            # https://segmentfault.com/q/1010000000377077 to match tag\n",
    "            m = re.search(r'(?<=<H3 FOLDED>)(.*?)(?=</H3>)', content)\n",
    "            if m:\n",
    "                # match for FOLDED node\n",
    "                val = m.group(0)\n",
    "                root = TreeNode.newTreeNode({\n",
    "                    \"type\": TreeNodeType.FOLDED,\n",
    "                    \"name\": val,\n",
    "                    \"level\": level,\n",
    "                })      \n",
    "                # 1. read next line \"<DL><p>\"\n",
    "                nextline = f.readline().decode('utf-8').strip()\n",
    "                assert nextline == \"<DL><p>\"\n",
    "                # 2. recursively process for tree node\n",
    "                self.newTree(f, level+1, root)\n",
    "                # 3. read end line \"</DL><p>\"\n",
    "                endline = f.readline().decode('utf-8').strip()\n",
    "                assert endline == \"</DL><p>\"\n",
    "            else:\n",
    "                m1 = re.search(r'(?<=<A HREF=)(.*?)(?=</A>)', content)\n",
    "                if m1:\n",
    "                    url, val = m1.group(0).split(\">\") \n",
    "                    # remove \"\" for url\n",
    "                    url = url[1:-1]\n",
    "                    root = TreeNode.newTreeNode({\n",
    "                        \"type\": TreeNodeType.LINK,\n",
    "                        \"name\": val,\n",
    "                        \"link\": url,\n",
    "                        \"level\": level,\n",
    "                    })\n",
    "                else:\n",
    "                    raise ValueError(\"invalid tag for tree node\")\n",
    "            if parent:\n",
    "                parent.appendChild(root)\n",
    "            return root\n",
    "        \n",
    "        # find the first <DT> in tree structure for FOLDER or HREF\n",
    "        l, align, fstart, existItem = findFirstDT(f)\n",
    "        roots = []\n",
    "        if existItem:\n",
    "            # only handle with item existing case\n",
    "            content = l[4:]\n",
    "            root = createNode(content, f, parent)\n",
    "            roots.append(root)\n",
    "\n",
    "            nl, nalgin, nfstart = findNextLineDT(f)\n",
    "            while (align == nalgin) and (nl[:4] == '<DT>'): \n",
    "                # if it's in the same level, already item for nextline\n",
    "                content = nl[4:]\n",
    "                root = createNode(content, f, parent)\n",
    "                roots.append(root)\n",
    "                nl, nalgin, nfstart = findNextLineDT(f)\n",
    "            else:\n",
    "                # else if it's not in the same level, somehow need to rollback\n",
    "                f.seek(nfstart, os.SEEK_SET)\n",
    "        return roots\n",
    "                \n",
    "    def preOrder(self, verifyURL: bool=False):\n",
    "        def preOrderTree(node: TreeNode):\n",
    "            if node:\n",
    "                if node.val[\"type\"] == TreeNodeType.LINK:\n",
    "                    if node.val[\"link\"] not in self.conflict_dict:\n",
    "                        self.conflict_dict[node.val[\"link\"]] = 1\n",
    "                    else:\n",
    "                        self.conflict_dict[node.val[\"link\"]] += 1\n",
    "                        self.duplicate_total += 1\n",
    "                    self.t += 1\n",
    "                    self.total_urls.append(node.val[\"link\"])\n",
    "                    if verifyURL:\n",
    "                        # if verification is enabled\n",
    "                        if node.val[\"link\"] not in self.validurls:\n",
    "                            try:\n",
    "                                with urllib.request.urlopen(node.val[\"link\"]) as response:\n",
    "                                    if response.getcode() == 200:\n",
    "                                        self.validurls.append(node.val[\"link\"])\n",
    "                            except HTTPError as ex:\n",
    "                                self.invalidurl_dict[node.val[\"link\"]] = ex.code\n",
    "                            except URLError as ex:\n",
    "                                self.invalidurl_dict[node.val[\"link\"]] = ex.strerror\n",
    "                for child in node.children:\n",
    "                    preOrderTree(child)\n",
    "        \n",
    "        def verifyUrls():\n",
    "            urls = []\n",
    "            with open(self.fname, 'rt') as f:\n",
    "                for line in f:\n",
    "                    m1 = re.search(r'(?<=<A HREF=)(.*?)(?=</A>)', line)\n",
    "                    if m1:\n",
    "                        url, val = m1.group(0).split(\">\") \n",
    "                        # remove \"\" for url\n",
    "                        url = url[1:-1]\n",
    "                        urls.append(url)\n",
    "            return urls\n",
    "                  \n",
    "        self.conflict_dict = {}; self.t = 0; self.duplicate_total = 0; self.total_urls = []; \n",
    "        self.validurls = []; self.invalidurl_dict = {}\n",
    "        for root in self.roots:\n",
    "            preOrderTree(root)\n",
    "        \n",
    "        # verify if tree's url are equal with file url\n",
    "        _urls = verifyUrls()\n",
    "        assert len(self.total_urls) == len(_urls)\n",
    "        for turl in _urls:\n",
    "            assert turl in forest.total_urls\n",
    "        \n",
    "        # return key figure to client\n",
    "        if verifyURL:\n",
    "            return self.t, self.duplicate_total, self.conflict_dict, self.validurls, self.invalidurl_dict\n",
    "        else:\n",
    "            return self.t, self.duplicate_total, self.conflict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of url link:  4986\n",
      "number of duplicate url out of total url link:  613\n",
      "max duplicate number of url link:  5\n"
     ]
    }
   ],
   "source": [
    "forest = Forest(data_loc)\n",
    "total_urls, duplicate_urls, conflict_dict = forest.preOrder()\n",
    "print(\"total number of url link: \", total_urls)\n",
    "print(\"number of duplicate url out of total url link: \", duplicate_urls)\n",
    "duplicate_dict = {k:v for k, v in conflict_dict.items() if v > 1}\n",
    "print(\"max duplicate number of url link: \", max(duplicate_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4373/4373 [21:42<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from socket import timeout\n",
    "import ssl\n",
    "ssl.match_hostname = lambda cert, hostname: True\n",
    "\n",
    "proxies = {\n",
    "    'http': 'http://proxy.hkg.sap.corp:8080',\n",
    "    'https': 'http://proxy.hkg.sap.corp:8080',\n",
    "    'no': \"localhost,*.sap.corp\"\n",
    "    }\n",
    "\n",
    "proxy = urllib.request.ProxyHandler(proxies)\n",
    "opener = urllib.request.build_opener(proxy)\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "def verify(arg):\n",
    "    index, url = arg\n",
    "    valid = False; msg = None; \n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            if response.getcode() == 200:\n",
    "                valid = True\n",
    "                msg = url\n",
    "            else:\n",
    "                msg = response.getcode()\n",
    "    except HTTPError as ex:\n",
    "        msg = ex.code\n",
    "    except URLError as ex:\n",
    "        msg = ex.strerror\n",
    "    except IncompleteRead as ex:\n",
    "        msg = ex\n",
    "    except timeout as ex:\n",
    "        msg = ex\n",
    "    return index, valid, msg\n",
    "\n",
    "# using multiprocessing to check url validation\n",
    "urls = list(conflict_dict.keys())\n",
    "urls_status = [None] * len(urls)\n",
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    # refer to https://github.com/tqdm/tqdm#iterable-based#user-content-usage and https://stackoverflow.com/questions/37506645/can-i-add-message-to-the-tqdm-progressbar/37523994\n",
    "    for index, valid, msg in tqdm(executor.map(verify,  enumerate(urls)), total=len(urls)):\n",
    "        urls_status[index] = (valid, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_urls_list = [url for status, url in urls_status if status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_urls_dict = {urls[index]: desc for index, (status, desc) in enumerate(urls_status) if not status}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid_urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/valid_urls_list.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(valid_urls_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"data/invalid_urls_dict.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(invalid_urls_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(invalid_urls_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2885"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redirection to others, if code == 503\n",
    "len({x:y for x, y in invalid_urls_dict.items() if y==503})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
